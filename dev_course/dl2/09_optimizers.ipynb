{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_08 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenette data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We grab the data from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
    "il = ImageItemList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
    "ll = label_by_func(sd, parent_labeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,valid_dl = get_dls(ll.train,ll.valid,bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x[0])\n",
    "ll.train.y.processor.vocab[y[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [32,64,128,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.25, 0.75], [sched_cos(0.4/25, 0.4), sched_cos(0.4, 0.)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [partial(AvgStatsCallback,accuracy),\n",
    "        CudaCallback,\n",
    "        partial(BatchTransformXCallback, norm_imagenette),\n",
    "        partial(ParamScheduler, 'lr', sched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl, valid_dl, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the baseline of training with vanilla SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight decay comes from the idea of L2 regularization, which consists in adding to your loss function the sum of all the weights squared. Why do that? Because when we compute the gradients, it will add a contribution to them that will encourage the weights to be as small as possible.\n",
    "\n",
    "Why would it prevent overfitting? The idea is that the larger the coefficient are, the more sharp canyons we will have in the loss function. If we take the basic example of parabola, `y = a * (x**2)`, the larger `a` is, the more *narrow* the parabola is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-2,2,100)\n",
    "a_s = [1,2,5,10,50] \n",
    "ys = [a * x**2 for a in a_s]\n",
    "_,ax = plt.subplots()\n",
    "for a,y in zip(a_s,ys): ax.plot(x,y, label=f'a={a}')\n",
    "ax.set_ylim([0,5])\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by letting our model learn high parameters, it might fit all the data points in the training set with an over-complex function that has very sharp changes, which will lead to overfitting.\n",
    "\n",
    "<img src=\"images/overfit.png\" alt=\"Fitting vs over-fitting\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limiting our weights from growing to much is going to hinder the training of the model, but it will yield to a state where it generalizes better. Going back to the theory a little bit, weight decay (or just `wd`) is a parameter that controls that sum of squares we add to our loss:\n",
    "``` python\n",
    "loss_with_wd = loss + (wd / 2) * sum([(p ** 2).sum() for p in model_parameters])\n",
    "```\n",
    "\n",
    "In practice though, it would be very inefficient (and maybe numerically unstable) to compute that big sum and add it to the loss. If you remember a little bit of high schoool math, you should now that the derivative of `p ** 2` with respect to `p` is simple `2 * p`, so adding that big sum to our loss is exactly the same as doing\n",
    "``` python\n",
    "weight.grad += wd * weight\n",
    "```\n",
    "\n",
    "for every weight in our model, which is equivalent to (in the case of vanilla SGD) updating the parameters\n",
    "with\n",
    "``` python\n",
    "new_weight = weight - lr * weight.grad - lr * wd * weight\n",
    "```\n",
    "\n",
    "This last formula explains why the name of this technique is weight decay, as each weight is decayed by a factor `lr * wd`. \n",
    "\n",
    "This only works for standard SGD, as we have seen that with momentum, RMSProp or in Adam, the update has some additional formulas around the gradient. In those cases, the formula that comes from L2 regularization:\n",
    "``` python\n",
    "weight.grad += wd * weight\n",
    "```\n",
    "is different than weight decay\n",
    "``` python\n",
    "new_weight = weight - lr * weight.grad - lr * wd * weight\n",
    "```\n",
    "\n",
    "Most libraries use the first one, but as it was pointed out in [Decoupled Weight Regularization](https://arxiv.org/pdf/1711.05101.pdf) by Ilya Loshchilov and Frank Hutter, it is better to use the second one with the Adam optimizer, which is why fastai made it its default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(optim.Optimizer):\n",
    "    def __init__(self, params, steppers, **defaults): \n",
    "        super().__init__(params, defaults)\n",
    "        self.steppers = listify(steppers)\n",
    "        \n",
    "    def step(self):\n",
    "        for pg in self.param_groups:\n",
    "            for p in pg['params']:\n",
    "                if p.grad is not None: compose(p, self.steppers, pg=pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight decay is substracting `lr x wd x weights` to the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDecay():\n",
    "    _defaults = dict(wd=0.)\n",
    "    def __call__(self,p,pg):\n",
    "        p.data.mul_(1 - pg['lr'] * pg['wd'])\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization is adding `wd x weight` to the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2_Reg():\n",
    "    _defaults = dict(wd=0.)\n",
    "    def __call__(self,p,pg):\n",
    "        p.grad.data.add_(pg['wd'], p.data)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the classic SGD step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_step(p, pg):\n",
    "    p.data.add_(-pg['lr'], p.grad.data)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stepper may introduce new hyperparameters so we associate a `_defaults` variable to it to make sure it's present in the param groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Optimizer(optim.Optimizer):\n",
    "    def __init__(self, params, steppers, **defaults): \n",
    "        self.steppers = listify(steppers)\n",
    "        stepper_defaults = {}\n",
    "        for stepper in self.steppers: stepper_defaults.update(getattr(stepper,'_defaults',{}))\n",
    "        super().__init__(params, {**stepper_defaults, **defaults})\n",
    "        \n",
    "    def step(self):\n",
    "        for pg in self.param_groups:\n",
    "            for p in pg['params']:\n",
    "                if p.grad is not None: compose(p, self.steppers, pg=pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(Optimizer, steppers=[WeightDecay(), sgd_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt_func(model.parameters(), lr=0.1)\n",
    "opt.param_groups[0]['wd'],opt.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt_func(model.parameters(), lr=0.1, wd=1e-4)\n",
    "opt.param_groups[0]['wd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs, opt_func=partial(opt_func, wd=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum requires to add some state. We need to save the moving average of the gradients to be able to do the step and store this inside the optimizer state if we want it saved by PyTorch (when doing checkpointing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatefulOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, steppers, stats=None, **defaults): \n",
    "        self.steppers,self.stats = listify(steppers),listify(stats)\n",
    "        base_defaults = {}\n",
    "        for stepper in self.steppers: base_defaults.update(getattr(stepper,'_defaults',{}))\n",
    "        for stat in self.stats:       base_defaults.update(getattr(stat,'_defaults',{}))\n",
    "        super().__init__(params, {**base_defaults, **defaults})\n",
    "        \n",
    "    def step(self):\n",
    "        for pg in self.param_groups:\n",
    "            for p in pg['params']:\n",
    "                if p.grad is not None:\n",
    "                    if p not in self.state:\n",
    "                        init_state = {}\n",
    "                        for stat in self.stats: init_state.update(stat.init_state(p))\n",
    "                        self.state[p] = init_state\n",
    "                    state = self.state[p]\n",
    "                    for stat in self.stats: state = stat.update(p, pg, state)\n",
    "                    compose(p, self.steppers, pg=pg, state=state)\n",
    "                    self.state[p] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Stat():\n",
    "    _defaults = {}\n",
    "    def init_state(self, p):        raise NotImplementedError\n",
    "    def update(self, p, pg, state): raise NotImplementedError    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AverageGrad(Stat):\n",
    "    _defaults = dict(mom=0.9)\n",
    "\n",
    "    def init_state(self, p): return {'grad_avg': torch.zeros_like(p.grad.data)}\n",
    "    def update(self, p, pg, state):\n",
    "        state['grad_avg'].mul_(pg['mom']).add_(p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the previous classes/functions to take the new `state` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WeightDecay():\n",
    "    _defaults = dict(wd=0.)\n",
    "    def __call__(self,p,pg,state):\n",
    "        p.data.mul_(1 - pg['lr'] * pg['wd'])\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class L2_Reg():\n",
    "    _defaults = dict(wd=0.)\n",
    "    def __call__(self,p,pg,state):\n",
    "        p.grad.data.add_(pg['wd'], p.data)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sgd_step(p, pg,state):\n",
    "    p.data.add_(-pg['lr'], p.grad.data)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add the momentum step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def momentum_step(p, pg, state):\n",
    "    p.data.add_(-pg['lr'], state['grad_avg'])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_mom = partial(StatefulOptimizer, steppers=momentum_step, stats=AverageGrad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs, opt_func=sgd_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does momentum do to the gradients exactly? Let's do some plots to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-4, 4, 200)\n",
    "y = torch.randn(200) + 0.3\n",
    "betas = [0.5,0.7,0.9,0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mom(f):\n",
    "    _,axs = plt.subplots(2,2, figsize=(12,8))\n",
    "    for beta,ax in zip(betas, axs.flatten()):\n",
    "        ax.plot(y, linestyle='None', marker='.')\n",
    "        avg,res = None,[]\n",
    "        for i,yi in enumerate(y):\n",
    "            avg,p = f(avg, beta, yi, i)\n",
    "            res.append(p)\n",
    "        ax.plot(res, color='red')\n",
    "        ax.set_title(f'beta={beta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the regular momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom1(avg, beta, yi, i): \n",
    "    if avg is None: avg=yi\n",
    "    res = beta * avg + yi\n",
    "    return res,res\n",
    "plot_mom(mom1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with a too high value, it may go way too high with no way to change its course.\n",
    "\n",
    "Another way to smooth noisy data is to do an exponentially moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom2(avg, beta, yi, i):\n",
    "    if avg is None: avg=yi\n",
    "    avg = beta * avg + (1-beta) * yi\n",
    "    return avg, avg\n",
    "plot_mom(mom2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see it gets to a zero-constant when the data is purely random. If the data has a certain shape, it will get that shape (with some delay for high beta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1 - (x/3) ** 2 + torch.randn(200) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mom(mom2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debiasing is here to correct the wrong information we may have in the very first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom3(avg, beta, yi, i):\n",
    "    if avg is None: avg=0\n",
    "    avg = beta * avg + (1-beta) * yi\n",
    "    return avg, avg/(1-beta**(i+1))\n",
    "plot_mom(mom3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam and friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Adam, we use the gradient averages but with dampening, so let's add this to the `AverageGrad` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AverageGrad(Stat):\n",
    "    _defaults = dict(mom=0.9)\n",
    "    \n",
    "    def __init__(self, dampening:bool=False): self.dampening=dampening\n",
    "    def init_state(self, p): return {'grad_avg': torch.zeros_like(p.grad.data)}\n",
    "    def update(self, p, pg, state):\n",
    "        pg['mom_damp'] = 1 - pg['mom'] if self.dampening else 1.\n",
    "        state['grad_avg'].mul_(pg['mom']).add_(pg['mom_damp'], p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to track the moving average of the gradients squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AverageSqrGrad(Stat):\n",
    "    _defaults = dict(sqr_mom=0.99)\n",
    "    \n",
    "    def __init__(self, dampening:bool=True): self.dampening=dampening\n",
    "    def init_state(self, p): return {'sqr_avg': torch.zeros_like(p.grad.data)}\n",
    "    def update(self, p, pg, state):\n",
    "        pg['sqr_damp'] = 1 - pg['sqr_mom'] if self.dampening else 1.\n",
    "        state['sqr_avg'].mul_(pg['sqr_mom']).addcmul_(pg['sqr_damp'],p.grad.data,p.grad.data)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the number of steps done during training for the debiasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StepCount(Stat):\n",
    "    def init_state(self, p): return {'step': 0}\n",
    "    def update(self, p, pg, state):\n",
    "        state['step'] += 1\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def debias(mom, damp, step): return damp * (1 - mom**step) / (1-mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Adam step is just the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdamStep():\n",
    "    _defaults = dict(eps=1e-5)\n",
    "    def __call__(self, p, pg, state):\n",
    "        debias1 = debias(pg['mom'],     pg['mom_damp'], state['step'])\n",
    "        debias2 = debias(pg['sqr_mom'], pg['sqr_damp'], state['step'])\n",
    "        p.data.addcdiv_(-pg['lr'] / debias1, state['grad_avg'], (state['sqr_avg']/debias2 + pg['eps']).sqrt())\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = partial(StatefulOptimizer, steppers=AdamStep(), stats=[AverageGrad(dampening=True), AverageSqrGrad(), StepCount()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.1, conv_layer, cbs=cbfs, opt_func=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then super easy to implement a new optimizer. This is LAMB from a [very recent paper](https://arxiv.org/pdf/1904.00962.pdf):\n",
    "\n",
    "$\\begin{align}\n",
    "g_{t}^{l} &= \\nabla L(w_{t-1}^{l}, x_{t}) \\\\\n",
    "m_{t}^{l} &= \\beta_{1} m_{t-1}^{l} + (1-\\beta_{1}) g_{t}^{l} \\\\\n",
    "v_{t}^{l} &= \\beta_{2} v_{t-1}^{l} + (1-\\beta_{2}) g_{t}^{l} \\odot g_{t}^{l} \\\\\n",
    "m_{t}^{l} &= m_{t}^{l} / (1 - \\beta_{1}^{t}) \\\\\n",
    "v_{t}^{l} &= v_{t}^{l} / (1 - \\beta_{2}^{t}) \\\\\n",
    "r_{1} &= \\|w_{t-1}^{l}\\|_{2} \\\\\n",
    "s_{t}^{l} &= \\frac{m_{t}^{l}}{\\sqrt{v_{t}^{l} + \\epsilon}} + \\lambda w_{t-1}^{l} \\\\ \n",
    "r_{2} &= \\| s_{t}^{l} \\|_{2} \\\\\n",
    "\\eta^{l} &= \\eta * r_{1}/r_{2} \\\\ \n",
    "w_{t}^{l} &= w_{t}^{l-1} - \\eta_{l} * s_{t}^{l} \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambStep():\n",
    "    _defaults = dict(eps=1e-6, wd=0.)\n",
    "    def __call__(self, p, pg, state):\n",
    "        debias1 = debias(pg['mom'],     pg['mom_damp'], state['step'])\n",
    "        debias2 = debias(pg['sqr_mom'], pg['sqr_damp'], state['step'])\n",
    "        r1 = p.data.pow(2).mean().sqrt()\n",
    "        step = (state['grad_avg']/ debias1) / (state['sqr_avg']/debias2 + pg['eps']).sqrt() + pg['wd'] * p.data\n",
    "        r2 = step.pow(2).mean().sqrt()\n",
    "        p.data.add_(-pg['lr'] * min(r1/r2,10), step)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = partial(StatefulOptimizer, steppers=LambStep(), stats=[AverageGrad(dampening=True), AverageSqrGrad(), StepCount()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs, opt_func=lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other recent variants of optimizers:\n",
    "- [Large Batch Training of Convolutional Networks](https://arxiv.org/abs/1708.03888) (LARS also uses weight statistics, not just gradient statistics. Can you add that to this class?)\n",
    "- [Adafactor: Adaptive Learning Rates with Sublinear Memory Cost](https://arxiv.org/abs/1804.04235) (Adafactor combines stats over multiple sets of axes)\n",
    "- [Adaptive Gradient Methods with Dynamic Bound of Learning Rate](https://arxiv.org/abs/1902.09843)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python notebook2script.py 09_optimizers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
